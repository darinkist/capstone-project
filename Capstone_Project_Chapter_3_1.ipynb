{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('store_v2.p', 'rb')\n",
    "store = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ids = store.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KPIs\n",
    "\n",
    "def calc_kpis(actuals, predictions, seasonality=7):\n",
    "    \n",
    "    #Experemential\n",
    "    try:\n",
    "        actuals.reset_index(drop=True,inplace=True)\n",
    "        predictions.reset_index(drop=True,inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mae_kpi = mean_absolute_error(actuals, predictions)\n",
    "    \n",
    "    rmse_kpi = sqrt(mean_squared_error(actuals, predictions))\n",
    "    \n",
    "    mase_kpi = (mean_absolute_error(actuals, predictions) / \n",
    "                mean_absolute_error(actuals[seasonality:], actuals[:-seasonality]))\n",
    "    \n",
    "    #smape_kpi = np.sum(np.absolute(actuals - predictions)/((np.absolute(actuals)+np.absolute(predictions))/2))*(100/len(predictions))\n",
    "    \n",
    "    smape_kpi=np.sum(np.absolute(actuals - predictions)/((np.absolute(actuals)+np.absolute(predictions))/2))*(100/len(predictions))\n",
    "    \n",
    "    return mae_kpi, rmse_kpi, mase_kpi, smape_kpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_kpis(store_id,model_name,kpis):\n",
    "    \n",
    "    model_performance.loc[(store_id,model_name),[\"mae\"]] = kpis[0] # \"mae_kpi\"\n",
    "    model_performance.loc[(store_id,model_name),[\"rmse\"]] = kpis[1] # rmse_kpi\n",
    "    model_performance.loc[(store_id,model_name),[\"mase\"]] = kpis[2] # mase_kpi\n",
    "    model_performance.loc[(store_id,model_name),[\"smape\"]] = kpis[3] # smape_kpi    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup df to store model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"bl_naive2\", \"sarima\", \"prophet\"]\n",
    "multi_index = [store_ids,models]\n",
    "kpis = [\"mae\",\"rmse\",\"mase\",\"smape\",\"rel_mase\", \"rel_smape\", \"owa\",\"rank\"]\n",
    "model_performance = pd.DataFrame(index=pd.MultiIndex.from_product(multi_index, names=['store', 'model']), columns=kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SNAIVE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SNAIVE2 Baseline Model (S)ARIMA(X)(0,0,0)x(0,1,0)\n",
    "def bl_naive2(data):\n",
    "    \n",
    "    data_train = data.loc[data[\"train_set\"]==True,[\"Sales\"]]\n",
    "    data_test = data.loc[data[\"train_set\"]==False,\"Sales\"]\n",
    "    \n",
    "    pred_start = data_train.index.max() + pd.DateOffset(1)\n",
    "    pred_end = data_test.index.max()\n",
    "    \n",
    "    model = sm.tsa.statespace.SARIMAX(\n",
    "        data_train,\n",
    "        order=(0,0,0),\n",
    "        seasonal_order=(0,1,0,7)\n",
    "    ).fit()\n",
    "    \n",
    "    y_hat = model.get_prediction(\n",
    "        start=pred_start,\n",
    "        end=pred_end,\n",
    "        dynamic=False\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        pred = y_hat.predicted_mean,\n",
    "        kpis = calc_kpis(data_test, y_hat.predicted_mean, 7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def apply_bl_naive2(data):\n",
    "    store_result = bl_snaive2(store[store_id])\n",
    "    store_kpis(store_id,\"bl_naive2\",store_result[\"kpis\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TESTING\n",
    "#bl_snaive2(store[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for store_id in store_ids:\n",
    "    print(\"Applying NAIVE2 for store #\"+str(store_id)+\" out of \"+ str(len(store_ids)))\n",
    "    apply_bl_naive2(store[store_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define possible combinations\n",
    "# Use only 12 combinations\n",
    "## ARIMA(2, d, 2)(1, D, 1)\n",
    "## ARIMA(0, d, 0)(0, D, 0)\n",
    "## ARIMA(1, d, 0)(1, D, 0)\n",
    "## ARIMA(0, d, 1)(0, D, 1)\n",
    "\n",
    "#[(2, d, 2), (1, D, 1, 7)],\n",
    "#[(0, d, 0), (0, D, 0, 7)],\n",
    "#[(1, d, 0), (1, D, 0, 7)],\n",
    "#[(0, d, 1), (0, D, 1, 7)],\n",
    "def create_model_cfgs():\n",
    "    return(np.array([\n",
    "    [(2, 0, 2), (1, 0, 1, 7)],\n",
    "    [(2, 1, 2), (1, 1, 1, 7)],\n",
    "    [(2, 0, 2), (1, 1, 1, 7)],\n",
    "    [(2, 1, 2), (1, 0, 1, 7)],\n",
    "\n",
    "    [(0, 0, 0), (0, 0, 0, 7)],\n",
    "    [(0, 1, 0), (0, 1, 0, 7)],\n",
    "    [(0, 0, 0), (0, 1, 0, 7)],\n",
    "    [(0, 1, 0), (0, 0, 0, 7)],\n",
    "\n",
    "    [(1, 0, 0), (1, 0, 0, 7)],\n",
    "    [(0, 1, 1), (0, 1, 1, 7)],\n",
    "    [(0, 0, 1), (0, 1, 1, 7)],\n",
    "    [(0, 1, 1), (0, 0, 1, 7)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define SARIMA function to get AIC\n",
    "def simulate_sarima(data, cfg):\n",
    "    print(\"simulate \"+str(cfg))\n",
    "    order, sorder = cfg\n",
    "    data_train = data.loc[data[\"train_set\"]==True,[\"Sales\"]]\n",
    "    try:\n",
    "        fit = sm.tsa.statespace.SARIMAX(data_train, order=order, seasonal_order=sorder).fit()\n",
    "        return (cfg, fit.aic)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run all possible combinations and return best configuration\n",
    "def find_best_parameters(data):\n",
    "    model_cfgs = create_model_cfgs()\n",
    "    #scores = list()\n",
    "    #for cfg in model_cfgs:\n",
    "    #    scores.append(simulate_sarima(data, cfg))\n",
    "        \n",
    "    executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "    tasks = (delayed(simulate_sarima)(data, cfg) for cfg in model_cfgs)\n",
    "    scores = executor(tasks)\n",
    "    \n",
    "    # Step 4: Select best model cfg\n",
    "    scores = [r for r in scores if r != None] #clean Nones\n",
    "    scores.sort(key=lambda x: x[1])\n",
    "    params, aic = scores[0]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Apply SARIMA with best parameters\n",
    "def sarima(data,y=\"Sales\"):\n",
    "    \n",
    "    print(\"Finding best parameters to forecast \" + y)\n",
    "    b_pdq, b_spdq = find_best_parameters(data) # find best parameters\n",
    "    \n",
    "    print(\"Best parameters have been found:\")\n",
    "    print(str(b_pdq) + str(b_spdq))\n",
    "    \n",
    "    data_train = data.loc[data[\"train_set\"]==True,[y]]\n",
    "    data_test = data.loc[data[\"train_set\"]==False,y]\n",
    "    \n",
    "    pred_start = data_train.index.max() + pd.DateOffset(1)\n",
    "    pred_end = data_test.index.max()\n",
    "    \n",
    "    print(\"Fitting model\")\n",
    "    model = sm.tsa.statespace.SARIMAX(\n",
    "        data_train,\n",
    "        order=b_pdq,\n",
    "        seasonal_order=b_spdq\n",
    "    ).fit()\n",
    "    \n",
    "    print(\"Forecasting future\")\n",
    "    y_hat = model.get_prediction(\n",
    "        start=pred_start,\n",
    "        end=pred_end,\n",
    "        dynamic=False\n",
    "    )\n",
    "    print(\"DONE\")\n",
    "    return dict(\n",
    "        pred = y_hat.predicted_mean,\n",
    "        kpis = calc_kpis(data_test, y_hat.predicted_mean, 7)\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sarima(data,y=\"Sales\"):\n",
    "    store_result = sarima(store[store_id],y)\n",
    "    store_kpis(store_id,\"sarima\",store_result[\"kpis\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "#%%time\n",
    "#results = apply_sarima(store[13],\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#for store_id in store_ids:\n",
    "for store_id in store_ids:\n",
    "    print(\"Applying SARIMA for store #\"+str(store_id)+\" out of \"+ str(len(store_ids)))\n",
    "    apply_sarima(store[store_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FB Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits to https://www.kaggle.com/elenapetrova/time-series-analysis-and-forecasts-with-prophet\n",
    "def get_holiday_df(df):\n",
    "    state_dates = df[(df.StateHoliday == 'a') | (df.StateHoliday == 'b') & (df.StateHoliday == 'c')].loc[:, 'Date'].values\n",
    "    school_dates = df[df.SchoolHoliday == 1].loc[:, 'Date'].values\n",
    "    state = pd.DataFrame({'holiday': 'state_holiday',\n",
    "                      'ds': pd.to_datetime(state_dates)})\n",
    "    school = pd.DataFrame({'holiday': 'school_holiday',\n",
    "                          'ds': pd.to_datetime(school_dates)})\n",
    "    return pd.concat((state, school))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_univariate(df, y, fb_holidays):\n",
    "    \n",
    "    fb_train = df.loc[df.train_set==True,[\"ds\",y]]\n",
    "    fb_train.columns = (\"ds\",\"y\")\n",
    "    \n",
    "    m = Prophet(holidays = fb_holidays, weekly_seasonality=True)\n",
    "    m.fit(fb_train)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=91,include_history = False)\n",
    "    forecast = m.predict(future)\n",
    "    return forecast[\"yhat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_prophet(df, exog=None):\n",
    "    \n",
    "    # Splitting up train and test set\n",
    "    fb_train = df.loc[df.train_set==True,]\n",
    "    fb_test = df.loc[df.train_set==False,]\n",
    "    \n",
    "    # Get holidays\n",
    "    fb_holidays = get_holiday_df(fb_train)\n",
    "    \n",
    "    # Rename for forecasting \n",
    "    fb_train.rename(columns={\"Date\": \"ds\", \"Sales\": \"y\"}, inplace=True)\n",
    "    \n",
    "    # Modeling\n",
    "    m = Prophet(holidays = fb_holidays, weekly_seasonality=True)\n",
    "    \n",
    "    # Adding regressors\n",
    "    if exog is not None:\n",
    "        for ex in exog:\n",
    "            m.add_regressor(ex)\n",
    "\n",
    "        \n",
    "    m.fit(fb_train)\n",
    "    \n",
    "    # Create future dataframe\n",
    "    future = m.make_future_dataframe(periods=91,include_history = False) #+1 to get the 90 days\n",
    "    \n",
    "    # Predicting regressors first\n",
    "    print(\"Predicting future values for exog regressors\")\n",
    "    if exog is not None:\n",
    "        for ex in exog:\n",
    "            future[ex] = fb_univariate(fb_train,ex,fb_holidays)\n",
    "    print(\"--done\")\n",
    "    \n",
    "    # Run forecast\n",
    "    print(\"Start with forecasting\")\n",
    "    forecast = m.predict(future)\n",
    "    print(\"--done\")\n",
    "    return dict(\n",
    "        pred = forecast[\"yhat\"],\n",
    "        kpis = calc_kpis(fb_test[\"Sales\"] , forecast[\"yhat\"],7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fb_prophet(df,exog=None):\n",
    "    store_result = fb_prophet(store[store_id],exog=None)\n",
    "    store_kpis(store_id,\"prophet\",store_result[\"kpis\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#for store_id in [13]:\n",
    "for store_id in store_ids:\n",
    "    print(\"Applying Prophet for store #\"+str(store_id)+\" out of \"+ str(len(store_ids)))\n",
    "    apply_fb_prophet(store[store_id],[\"Customers\",\"Promo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate OWA performance and ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_performance, open(\"model_performance.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for store_id in [1,2,3]:\n",
    "    for model in [\"bl_snaive2\", \"bl_sarima\", \"prophet\", \"sarimax\"]:\n",
    "        \n",
    "        model_performance.loc[(store_id, model),[\"rel_mase\"]] = (\n",
    "            model_performance.loc[(store_id, model),[\"mase\"]].values/\n",
    "            model_performance.loc[(store_id,\"bl_snaive2\"),[\"mase\"]].values\n",
    "        )\n",
    "    \n",
    "        model_performance.loc[(store_id, model),[\"rel_smape\"]] = (\n",
    "            model_performance.loc[(store_id, model),[\"smape\"]].values/\n",
    "            model_performance.loc[(store_id,\"bl_snaive2\"),[\"smape\"]].values\n",
    "        )\n",
    "        \n",
    "        model_performance.loc[(store_id, model),[\"owa\"]] = (\n",
    "            model_performance.loc[(store_id, model),[\"rel_mase\"]].values+\n",
    "            model_performance.loc[(store_id,\"bl_snaive2\"),[\"rel_smape\"]].values\n",
    "        )/2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for store_id in [1,2,3]:\n",
    "    model_performance.loc[(store_id,),[\"rank\"]] = model_performance.loc[(1,),[\"owa\"]].rank(method='min').values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_performance, open(\"model_performance_done.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
